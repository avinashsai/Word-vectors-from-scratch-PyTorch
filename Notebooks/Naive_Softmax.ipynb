{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive Softmax.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "u2IzNMsaorB-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import scipy\n",
        "from scipy.spatial.distance import cosine\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "d7IWMSMQq0im",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import collections\n",
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zWGz1Gb9zTVW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WaqkNwbtqu5g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corpus = []\n",
        "with open('train_pos.txt','r',encoding='latin1') as f:\n",
        "  for line in f.readlines():\n",
        "    corpus.append(line[:-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AV9mIdyHrAXg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "corpus = corpus[0:100]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ju6cgUzKrVwK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "length = len(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rnnaUWsurFCe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words = []\n",
        "for sentence in corpus:\n",
        "  words+=sentence.split()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dXOAb--IrKJD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab = list(set(words))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MCRHqIG8z55C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dy0p_rvbrMiq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fcd111bf-ebb4-40d8-add3-7411d85f924e"
      },
      "cell_type": "code",
      "source": [
        "vocab_len = len(vocab)\n",
        "print(vocab_len)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y_tUtclsro9g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word2idx = {}\n",
        "index = 0\n",
        "for word in vocab:\n",
        "  word2idx[word] = index\n",
        "  index+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XmB79OTGr0Oh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word2idx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sH3W-C2Yr6R2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx2word = {}\n",
        "index = 0\n",
        "for word in vocab:\n",
        "  idx2word[index] = word\n",
        "  index+=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cm_TWdcFsH3L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "idx2word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qkFxNiXdrNxw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "window_size = 2\n",
        "embedding_dim = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7oyHNKNHri8L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_corpus = []\n",
        "test_corpus = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5pavrTIHrRso",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for sentence in corpus:\n",
        "  words = sentence.split()\n",
        "  sent_len = len(words)\n",
        "  for i in range(sent_len):\n",
        "    for j in range(max(i-window_size,0),min(i+window_size,sent_len)):\n",
        "      train_corpus.append(word2idx[words[i]])\n",
        "      test_corpus.append(word2idx[words[j]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZIDAEkRetbiw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f64a931d-ebc6-43fc-f742-748ae5116a4a"
      },
      "cell_type": "code",
      "source": [
        "total_length = len(train_corpus)\n",
        "print(total_length)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94256\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EyhSTwHGtyaC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train = torch.zeros(total_length,vocab_len).to(device)\n",
        "test = torch.zeros(total_length).to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CxSj-sBeuEU4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(total_length):\n",
        "  train[i,train_corpus[i]] = 1\n",
        "  test[i] = test_corpus[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YUVubn6fuSzF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class naive_softmax(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(naive_softmax,self).__init__()\n",
        "    self.vocabsize = vocab_len\n",
        "    self.embeddingdim = embedding_dim\n",
        "    self.linear1 = nn.Linear(self.vocabsize,self.embeddingdim)\n",
        "    self.linear2 = nn.Linear(self.embeddingdim,self.vocabsize)\n",
        " \n",
        "  def forward(self,x):\n",
        "    out = self.linear1(x)\n",
        "    out = self.linear2(out)\n",
        "    out = F.log_softmax(out,dim=1)\n",
        "    return out\n",
        "    \n",
        "  def predict(self,x):\n",
        "    return self.linear1(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KMorTdrkwEkW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = naive_softmax().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Xn1IIYRpxIKq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8567692d-58aa-40b3-9771-11db11a83924"
      },
      "cell_type": "code",
      "source": [
        "modeltest = torch.zeros((3,vocab_len)).to(device)\n",
        "modeltest[0,0] = modeltest[1,1] = modeltest[2,2] = 1\n",
        "output = model(modeltest)\n",
        "print(output.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 4075])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KhNucfzswR-K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "traindata = torch.utils.data.TensorDataset(train,test)\n",
        "trainloader = torch.utils.data.DataLoader(traindata,batch_size=64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bXkkoE3lwv6t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(model.parameters(),lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eA3nc8Moy5Rr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "numepochs = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5VLKHPCgxEIK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1037
        },
        "outputId": "ef18e340-e725-4317-e9a0-89fa46079fd3"
      },
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(numepochs):\n",
        "  for i,(X,y) in enumerate(trainloader):\n",
        "    X,y = X.to(device),y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(X)\n",
        "    loss = F.nll_loss(output,y.long())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if(i%500==0):\n",
        "      print(\"Epoch {} Batch {} Loss {}\".format(epoch,i,loss))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 Batch 0 Loss 8.362159729003906\n",
            "Epoch 0 Batch 500 Loss 8.293618202209473\n",
            "Epoch 0 Batch 1000 Loss 8.319917678833008\n",
            "Epoch 1 Batch 0 Loss 8.339107513427734\n",
            "Epoch 1 Batch 500 Loss 8.281229019165039\n",
            "Epoch 1 Batch 1000 Loss 8.308741569519043\n",
            "Epoch 2 Batch 0 Loss 8.316291809082031\n",
            "Epoch 2 Batch 500 Loss 8.268821716308594\n",
            "Epoch 2 Batch 1000 Loss 8.297411918640137\n",
            "Epoch 3 Batch 0 Loss 8.293137550354004\n",
            "Epoch 3 Batch 500 Loss 8.256085395812988\n",
            "Epoch 3 Batch 1000 Loss 8.285645484924316\n",
            "Epoch 4 Batch 0 Loss 8.269087791442871\n",
            "Epoch 4 Batch 500 Loss 8.242704391479492\n",
            "Epoch 4 Batch 1000 Loss 8.273153305053711\n",
            "Epoch 5 Batch 0 Loss 8.243568420410156\n",
            "Epoch 5 Batch 500 Loss 8.228353500366211\n",
            "Epoch 5 Batch 1000 Loss 8.259608268737793\n",
            "Epoch 6 Batch 0 Loss 8.215962409973145\n",
            "Epoch 6 Batch 500 Loss 8.212663650512695\n",
            "Epoch 6 Batch 1000 Loss 8.244643211364746\n",
            "Epoch 7 Batch 0 Loss 8.185551643371582\n",
            "Epoch 7 Batch 500 Loss 8.195194244384766\n",
            "Epoch 7 Batch 1000 Loss 8.227799415588379\n",
            "Epoch 8 Batch 0 Loss 8.151505470275879\n",
            "Epoch 8 Batch 500 Loss 8.175407409667969\n",
            "Epoch 8 Batch 1000 Loss 8.208527565002441\n",
            "Epoch 9 Batch 0 Loss 8.112844467163086\n",
            "Epoch 9 Batch 500 Loss 8.152669906616211\n",
            "Epoch 9 Batch 1000 Loss 8.186151504516602\n",
            "Epoch 10 Batch 0 Loss 8.068450927734375\n",
            "Epoch 10 Batch 500 Loss 8.126230239868164\n",
            "Epoch 10 Batch 1000 Loss 8.159889221191406\n",
            "Epoch 11 Batch 0 Loss 8.017096519470215\n",
            "Epoch 11 Batch 500 Loss 8.095269203186035\n",
            "Epoch 11 Batch 1000 Loss 8.128897666931152\n",
            "Epoch 12 Batch 0 Loss 7.957667350769043\n",
            "Epoch 12 Batch 500 Loss 8.059035301208496\n",
            "Epoch 12 Batch 1000 Loss 8.092466354370117\n",
            "Epoch 13 Batch 0 Loss 7.889708995819092\n",
            "Epoch 13 Batch 500 Loss 8.017203330993652\n",
            "Epoch 13 Batch 1000 Loss 8.050468444824219\n",
            "Epoch 14 Batch 0 Loss 7.814713478088379\n",
            "Epoch 14 Batch 500 Loss 7.970583915710449\n",
            "Epoch 14 Batch 1000 Loss 8.004015922546387\n",
            "Epoch 15 Batch 0 Loss 7.738037586212158\n",
            "Epoch 15 Batch 500 Loss 7.921326160430908\n",
            "Epoch 15 Batch 1000 Loss 7.954859256744385\n",
            "Epoch 16 Batch 0 Loss 7.667838096618652\n",
            "Epoch 16 Batch 500 Loss 7.870004177093506\n",
            "Epoch 16 Batch 1000 Loss 7.9013566970825195\n",
            "Epoch 17 Batch 0 Loss 7.606590747833252\n",
            "Epoch 17 Batch 500 Loss 7.812423229217529\n",
            "Epoch 17 Batch 1000 Loss 7.83834171295166\n",
            "Epoch 18 Batch 0 Loss 7.548519611358643\n",
            "Epoch 18 Batch 500 Loss 7.745517253875732\n",
            "Epoch 18 Batch 1000 Loss 7.764679908752441\n",
            "Epoch 19 Batch 0 Loss 7.489089012145996\n",
            "Epoch 19 Batch 500 Loss 7.6712327003479\n",
            "Epoch 19 Batch 1000 Loss 7.6833977699279785\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dO2r350P1eWh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  vocabvec = []\n",
        "  vector = torch.zeros(vocab_len).to(device)\n",
        "  for i in range(vocab_len):\n",
        "      vector[i] = 1\n",
        "      vocabvec.append(model.predict(vector).cpu().numpy())\n",
        "      vector[i] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Mp1iyzX9zGEN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def find_similarwords(targetword,numwords):\n",
        "  with torch.no_grad():\n",
        "    cosinedis = []\n",
        "    vector = torch.zeros(vocab_len).to(device)\n",
        "    vector[word2idx[targetword]] = 1\n",
        "    targetvec = model.predict(vector)\n",
        "    for i in range(vocab_len):\n",
        "      cosinedis.append((cosine(targetvec,vocabvec[i]),i))\n",
        "    sorted_dis = sorted(cosinedis,key=lambda x:x[0])\n",
        "    simwords = []\n",
        "    for i in range(numwords):\n",
        "      simwords.append((sorted_dis[i][0],idx2word[i]))\n",
        "    return simwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IQ018W5J2ydP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "similarwords = find_similarwords('great',10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eC5D38IV23zz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e8e06b4d-c608-4e86-c50f-2d06002252ff"
      },
      "cell_type": "code",
      "source": [
        "similarwords"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.0, 'transition'),\n",
              " (7.927417755126953e-06, 'familial'),\n",
              " (1.2993812561035156e-05, 'verhoeven'),\n",
              " (1.3709068298339844e-05, 'vulnerable'),\n",
              " (1.5139579772949219e-05, 'summer'),\n",
              " (1.6450881958007812e-05, 'initially'),\n",
              " (1.7702579498291016e-05, 'smoochy'),\n",
              " (1.7702579498291016e-05, 'bizarrely'),\n",
              " (1.913309097290039e-05, 'kong'),\n",
              " (1.913309097290039e-05, 'becoming')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "metadata": {
        "id": "m7VNu2H-4U8f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}